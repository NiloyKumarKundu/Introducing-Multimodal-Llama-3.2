# Introducing-Multimodal-Llama-3.2

This repository summarizes my learnings from the **"Introducing Multimodal Llama 3.2"** course on DeepLearning.AI. The course explores Llama 3.2, a multimodal language model capable of processing both text and visual inputs. Key topics include:

- Overview of Llama 3.2
- Multimodal prompting and its use cases
- Effective prompt formatting and tokenization
- Tool calling and API integration
- Understanding the Llama stack and architecture

This course deepened my understanding of LLMs in multimodal contexts, with practical examples and real-world applications.
